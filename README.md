📌This project aims to develop a sequence-to-sequence (seq2seq) model that can take a PyTorch neural network as input and produce a clear textual summary explaining the input shape and output shape of the network. This solution addresses the problem faced by Joe, a machine learning enthusiast, who finds it challenging to explain the intricate details of his neural network models to his peers and stakeholders.
Features
✔️Synthetic data generation for training the seq2seq model
✔️Encoder-decoder architecture with LSTM layers
✔️Fully connected layer for output generation
✔️Evaluation of the model's performance on new neural networks
