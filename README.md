ğŸ“ŒThis project aims to develop a sequence-to-sequence (seq2seq) model that can take a PyTorch neural network as input and produce a clear textual summary explaining the input shape and output shape of the network. This solution addresses the problem faced by Joe, a machine learning enthusiast, who finds it challenging to explain the intricate details of his neural network models to his peers and stakeholders.
Features
âœ”ï¸Synthetic data generation for training the seq2seq model
âœ”ï¸Encoder-decoder architecture with LSTM layers
âœ”ï¸Fully connected layer for output generation
âœ”ï¸Evaluation of the model's performance on new neural networks
